{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "83ad3906",
   "metadata": {},
   "source": [
    "# <img style=\"float: left; padding-right: 10px; width: 45px\" src=\"https://raw.githubusercontent.com/Harvard-IACS/2018-CS109A/master/content/styles/iacs.png\"> CS109A Introduction to Data Science "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "38a1065e",
   "metadata": {},
   "source": [
    "# Lab 8: Decision Trees & Bagging\n",
    "\n",
    "**Harvard University**<br/>\n",
    "**Fall 2023**<br/>\n",
    "**Instructors**: Pavlos Protopapas and Kevin Rader<br/>\n",
    "<hr style='height:2px'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17c2fa4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#RUN THIS CELL \n",
    "import requests\n",
    "from IPython.core.display import HTML\n",
    "styles = requests.get(\"https://raw.githubusercontent.com/Harvard-IACS/2018-CS109A/master/content/styles/cs109.css\").text\n",
    "HTML(styles)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9edf42ad",
   "metadata": {},
   "source": [
    "Table of Contents:\n",
    "- A quick review of decision trees\n",
    "- `DecisionTreeClassifier`\n",
    "- Tuning a single decision tree (`max_depth` & `criterion`)\n",
    "- Vizualizing a decision tree with `plot_tree`)\n",
    "- Pruning\n",
    "- Motivating bagging\n",
    "- Out-of-Bag Error (OOB)\n",
    "- Feature Importance\n",
    "- `BaggingClassifier`"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "960031e3",
   "metadata": {},
   "source": [
    "---------\n",
    "\n",
    "#### The Idea: Decision Trees are just flowcharts and are interpretable!\n",
    "\n",
    "<img src=\"fig/flowchart.png\" alt=\"how to fix anything\" width=\"50%\"/>\n",
    "\n",
    "\n",
    "It turns out that simple flow charts can be formulated as mathematical models for classification and these models have the properties we desire:\n",
    " - interpretable by humans \n",
    " - have sufficiently complex decision boundaries \n",
    " - the decision boundaries are locally linear, each component of the decision boundary is simple to describe mathematically. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "972f76b3",
   "metadata": {},
   "source": [
    "----------\n",
    "\n",
    "#### Let's review some theory.\n",
    "\n",
    "How do we build decision trees? We use a greedy approach:\n",
    " 1. Start with an empty decision tree (undivided feature space) \n",
    " 2. Choose the ‚Äòoptimal‚Äô predictor on which to split and choose the ‚Äòoptimal‚Äô threshold value for splitting by applying a **splitting criterion (1)**\n",
    " 3. Recurse on on each new node until **stopping condition (2)** is met\n",
    " \n",
    "For classification, we label each region in the model with the label of the class to which the majority of the points within the region belong. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9910d491",
   "metadata": {},
   "source": [
    "#### So we need a (1) splitting criterion and a (2) stopping condition:\n",
    "\n",
    "  #### (1) Splitting criterion \n",
    "<img src=\"fig/split1.png\" alt=\"split1\" width=\"70%\"/>\n",
    "\n",
    "---\n",
    "\n",
    "<img src=\"fig/classification error.png\" alt=\"classification error\"/>\n",
    "\n",
    "---\n",
    "<img src=\"fig/split2.png\" alt=\"split2\" width=\"70%\"/>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e5240f13",
   "metadata": {},
   "source": [
    "<img src=\"fig/tree_loss.png\" alt=\"tree_adj\"/>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "621fd798",
   "metadata": {},
   "source": [
    "#### (2) Stopping condition\n",
    "\n",
    "If we don‚Äôt terminate the decision tree learning algorithm manually, the tree will continue to grow until each region defined by the model possibly contains exactly one training point (and the model attains 100% training accuracy). **Not stopping while building a deeper and deeper tree = 100% training accuracy; What will your test accuracy be? What can we do to fix this?**\n",
    "\n",
    "To prevent the **overfitting** from happening, we could \n",
    "- Stop the algorithm at a particular depth. (=**not too deep**)\n",
    "- Don't split a region if all instances in the region belong to the same class. (=**stop when subtree is pure**)\n",
    "- Don't split a region if the number of instances in the sub-region will fall below pre-defined threshold (min_samples_leaf). (=**not too specific/small subtree**)\n",
    "- Don't use too many splits in the tree (=**not too many splits / not too complex global tree**)\n",
    "- Be content with <100% accuracy training set...\n",
    "\n",
    "-------------\n",
    "\n",
    "#### Done with theory, let's get started"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b85afb2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "import sklearn.metrics as metrics\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "from sklearn import tree\n",
    "from sklearn.model_selection import train_test_split, learning_curve\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn import datasets\n",
    "\n",
    "#new model objects\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "\n",
    "\n",
    "pd.set_option('display.width', 1500)\n",
    "pd.set_option('display.max_columns', 100)\n",
    "\n",
    "np.random.seed(42)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c7002d3f",
   "metadata": {},
   "source": [
    "-------------\n",
    "\n",
    "# Part 1 : Decision Tree Spam Classifier"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2380d777",
   "metadata": {},
   "source": [
    "We will be working with a spam email dataset. The dataset has 57 predictors with a response variable called `Spam` that indicates whether an email is spam or not spam. The goal is to be able to create a classifier or method that acts as a spam filter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53699257",
   "metadata": {},
   "outputs": [],
   "source": [
    "spam_df = pd.read_csv('data/spam.csv')\n",
    "display(spam_df.head())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c53d296e",
   "metadata": {},
   "source": [
    "The predictors are all quantitative. They represent certain features  of an email like the frequency of the word 'discount.' The we will use the binary `spam` variable in the final column as our response for classification."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "71f17873",
   "metadata": {},
   "source": [
    "Link to description : https://archive.ics.uci.edu/ml/datasets/spambase"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c2ec49c8",
   "metadata": {},
   "source": [
    "### Split data into train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "667d70f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split spam_df into train and test data with a random seed of 109\n",
    "data_train, data_test = train_test_split(spam_df, random_state=0, test_size=.2, stratify=spam_df.spam)\n",
    "\n",
    "# Split predictor and response columns\n",
    "X_train, y_train = data_train.drop(['spam'], axis=1), data_train['spam']\n",
    "X_test , y_test  = data_test.drop(['spam'] , axis=1), data_test['spam']\n",
    "\n",
    "print(\"Shape of Training Set :\", data_train.shape)\n",
    "print(\"Shape of Testing Set :\" , data_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29904b92",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "da4b65f0",
   "metadata": {},
   "source": [
    "We can check that the proportion of spam cases is roughly evenly represented in both the training and test set.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25902454",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check Percentage of Spam in Train and Test Set\n",
    "pct_spam_tr = 100*y_train.mean()\n",
    "pct_spam_te = 100*y_test.mean()\n",
    "                                                  \n",
    "print(f\"Percentage of Spam in Training Set \\t : {pct_spam_tr:0.2f}%\")\n",
    "print(f\"Percentage of Spam in Testing Set \\t : {pct_spam_te:0.2f}%\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "71ca2892",
   "metadata": {},
   "source": [
    "-----------\n",
    "\n",
    "# Part 2 : Fitting an Optimal Single Decision Tree (by Depth) :"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d473b755",
   "metadata": {},
   "source": [
    "Here, for each candidate `max_depth` and `criterion` combination, we fit a single tree to our spam training data using 5-fold cross validation.\n",
    "\n",
    "We store the CV accuracy scores in a DataFrame along with the hyperparmeter settings that generated them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc97baae",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Find optimal depth of trees\n",
    "\n",
    "df = pd.DataFrame(columns=['criterion', 'depth', 'all_cv', 'mean_cv'])\n",
    "\n",
    "criterion = ['gini', 'entropy']\n",
    "\n",
    "first_depth = 2\n",
    "final_depth = 30\n",
    "step = 2\n",
    "\n",
    "results = []\n",
    "for cur_criterion in criterion:      \n",
    "    for max_depth in range(first_depth, final_depth+1, step):\n",
    "        dt = DecisionTreeClassifier(criterion=cur_criterion , max_depth=max_depth)\n",
    "        scores = cross_val_score(estimator=dt, X=X_train, y=y_train, cv=5, n_jobs=-1)\n",
    "        \n",
    "        cur_results = {'criterion': cur_criterion,\n",
    "                      'depth': max_depth,\n",
    "                      'all_cv': scores,\n",
    "                      'mean_cv': scores.mean()}\n",
    "        results.append(cur_results)\n",
    "df = pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd804c94",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "display(df)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e4a9e3bf",
   "metadata": {},
   "source": [
    "Some dataframe manipulations for our x,y construction for the plot below:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5bb90fdf",
   "metadata": {},
   "source": [
    "We can then visualize the validation accuracy for the different hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36564023",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(7, 4))\n",
    "\n",
    "plt.plot(df[df.criterion == 'gini'].depth,\n",
    "         df[df.criterion == 'gini'].mean_cv, 'b-', marker='o', alpha = 0.6, label='Gini')\n",
    "plt.plot(df[df.criterion == 'entropy'].depth,\n",
    "         df[df.criterion == 'entropy'].mean_cv, 'r-', marker='o', alpha = 0.6, label='Entropy')\n",
    "plt.ylabel(\"Cross Validation Accuracy\")\n",
    "plt.xlabel(\"Maximum Depth\")\n",
    "plt.title('Variation of Accuracy with Depth - Simple Decision Tree')\n",
    "plt.legend()\n",
    "plt.grid(alpha = 0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5e2ff4d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d4332592",
   "metadata": {},
   "source": [
    "### Let's visualize a plot with the Confidence Bands!"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6c23817a",
   "metadata": {},
   "source": [
    "Also, if we wanted to get **the Confidence Bands of these results**, how would we? It's as simple as a combination of getting variance using ```scores.std()``` and ```plt.fill_between()```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaee71ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gini = df[df['criterion'] == 'gini']\n",
    "df_entropy = df[df['criterion'] == 'entropy']\n",
    "\n",
    "x_gini = df_gini['depth'].values.astype(float)\n",
    "y_gini = df_gini['mean_cv'].values.astype(float)\n",
    "\n",
    "x_entropy = df_entropy['depth'].values.astype(float)\n",
    "y_entropy = df_entropy['mean_cv'].values.astype(float)\n",
    "\n",
    "stds_gini = np.array([ np.std(scores) for scores in df_gini['all_cv']], dtype = float) \n",
    "stds_entropy = np.array([ np.std(scores) for scores in df_entropy['all_cv']], dtype = float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9f31a1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 1, figsize=(8, 5))\n",
    "\n",
    "#Plot\n",
    "axes[0].fill_between(df.loc[df.criterion == 'gini'].depth, y_gini + stds_gini, \n",
    "                     y_gini - stds_gini, alpha=0.2)\n",
    "axes[0].plot(x_gini, y_gini, 'b-', marker='o')\n",
    "axes[0].set_ylabel(\"Cross Validation Accuracy\")\n",
    "axes[0].set_title('Variation of Accuracy with Depth - Single Decision Tree')\n",
    "axes[0].legend(['std','Gini'])\n",
    "axes[0].grid(alpha = 0.3)\n",
    "\n",
    "axes[1].fill_between(x_entropy, y_entropy + stds_entropy, \n",
    "                     y_entropy - stds_entropy, \n",
    "                     color = 'r', alpha=0.2)\n",
    "axes[1].plot(x_entropy, y_entropy, 'r-', marker='o')\n",
    "axes[1].set_ylabel(\"Cross Validation Accuracy\")\n",
    "axes[1].set_xlabel(\"Maximum Depth\")\n",
    "axes[1].legend(['std','Entropy'])\n",
    "axes[1].grid(alpha = 0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9acddc19",
   "metadata": {},
   "source": [
    "### Let's visualize a boxplot! (**Gini impurity** only)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "737021d5",
   "metadata": {},
   "source": [
    "If we want to display it as a boxplot we first construct a dataframe with all the scores and second we use ```sns.boxplot(...)```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d57d0800",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df_gini.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41904cd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = range(first_depth, final_depth + 1, step)\n",
    "\n",
    "plt.figure(figsize=(7,4))\n",
    "plt.boxplot([df_gini.loc[df_gini.depth==d, 'all_cv'].values[0] for d in ds])\n",
    "plt.scatter(range(1,len(ds)+1), df_gini.mean_cv, color='red', alpha=0.3, label='Mean CV Acc')\n",
    "plt.xticks(range(1,len(ds)+1), labels=ds)\n",
    "plt.ylabel(\"cross-validation accuracy\")\n",
    "plt.xlabel(\"max depth\")\n",
    "plt.title(\"Spam Classifier Trees (Gini)\")\n",
    "plt.grid(alpha = 0.3)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "52a3fba4",
   "metadata": {},
   "source": [
    "**Question:** Which depth are you going to pick?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "104f4f73",
   "metadata": {},
   "source": [
    "### Let's extract the best_depth value from these two dataframes, *df_gini* and *df_entropy*.\n",
    "\n",
    "We need to create the new variable *best_depth* for each dataframe. \n",
    "\n",
    "How to get the index of the maximum value from the given array?\n",
    "\n",
    "```hint: np.argmax(target array)```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48927920",
   "metadata": {},
   "outputs": [],
   "source": [
    "# What does this do?\n",
    "\n",
    "mean_CV_acc_gini = df_gini['mean_cv']\n",
    "mean_CV_acc_entropy = df_entropy['mean_cv']\n",
    "\n",
    "best_idx_gini = np.argmax(mean_CV_acc_gini)\n",
    "best_idx_entropy = np.argmax(mean_CV_acc_entropy)\n",
    "\n",
    "best_depth_gini = df_gini['depth'].iloc[best_idx_gini]\n",
    "best_depth_entropy = df_entropy['depth'].iloc[best_idx_entropy]\n",
    "\n",
    "print('The best depth based on Gini impurity was found to be: ', best_depth_gini)\n",
    "print('The best depth based on Entropy was found to be: ', best_depth_entropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17705761",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Evalaute the performance at the best depth\n",
    "model_tree_gini = DecisionTreeClassifier(max_depth=best_depth_gini, criterion = 'gini')\n",
    "model_tree_entropy = DecisionTreeClassifier(max_depth=best_depth_entropy, criterion ='entropy')\n",
    "\n",
    "model_tree_gini.fit(X_train, y_train)\n",
    "model_tree_entropy.fit(X_train, y_train)\n",
    "\n",
    "#Check Accuracy of Spam Detection in Train and Test Set (Gini Impurity)\n",
    "acc_trees_train_gini = accuracy_score(y_train, model_tree_gini.predict(X_train))\n",
    "acc_trees_test_gini  = accuracy_score(y_test,  model_tree_gini.predict(X_test))\n",
    "\n",
    "print(\"================ [Gini Impurity] ================\")\n",
    "print(\"Simple Decision Trees: Accuracy, Training Set \\t : {:.2%}\".format(acc_trees_train_gini))\n",
    "print(\"Simple Decision Trees: Accuracy, Testing Set \\t : {:.2%}\".format(acc_trees_test_gini))\n",
    "\n",
    "#Check Accuracy of Spam Detection in Train and Test Set (Entropy)\n",
    "acc_trees_train_entropy = accuracy_score(y_train, model_tree_entropy.predict(X_train))\n",
    "acc_trees_test_entropy = accuracy_score(y_test,  model_tree_entropy.predict(X_test))\n",
    "\n",
    "print(\"\\n================ [Entropy] ================\")\n",
    "print(\"Simple Decision Trees: Accuracy, Training Set \\t : {:.2%}\".format(acc_trees_train_entropy))\n",
    "print(\"Simple Decision Trees: Accuracy, Testing Set \\t : {:.2%}\".format(acc_trees_test_entropy))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6bf64352",
   "metadata": {},
   "source": [
    "### Let's visualize a confusion matrix with ```plot_confusion_matrix```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "bc07f7a1",
   "metadata": {},
   "source": [
    "#### How to visualize the classification result using a Confusion matrix? ####\n",
    "\n",
    "<img src=\"fig/confusion_matrix.png\" alt=\"classification error\" width=\"300\"/>\n",
    "\n",
    "<img src=\"fig/confusion_matrix2.png\" alt=\"classification error\" width=\"400\"/>\n",
    "\n",
    "*source: wikipedia*\n",
    "\n",
    "We can use the sklearn library function, **plot_confusion_matrix**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df630c34",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(14,8))\n",
    "ConfusionMatrixDisplay.from_estimator(model_tree_gini, X_test, y_test, cmap=plt.cm.Blues, ax = axes[0]);\n",
    "ConfusionMatrixDisplay.from_estimator(model_tree_entropy, X_test, y_test, cmap=plt.cm.Blues, ax = axes[1])\n",
    "axes[0].set_title('Simple Decision Tree - Gini')\n",
    "axes[1].set_title('Simple Decision Tree - Entropy')\n",
    "# plt.rc('font', size=18)\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "28837125",
   "metadata": {},
   "source": [
    "### How to visualize a Decision Tree with ```sklearn.tree.plot_tree```\n",
    "\n",
    "*Question:* Do you think this tree is interpretable? What do you think about a the maximal depth of the tree?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7ea99e6a",
   "metadata": {},
   "source": [
    "<!-- - Let's look at the resulting text ```decision_tree.dot``` -->"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6ec89419",
   "metadata": {},
   "source": [
    "<!-- - Let's convert our (hard to read) written decision tree (```decision_tree.dot```) into an intuitive image file format: ```image_tree.png```\n",
    "- <span style=\"color:red\">**NOTE:**</span> You might need to install the ```pydot``` package by typing the following command in your terminal: ```pip install pydot``` or you can install from within the jupyter notebook by running the following cell: ```! pip install pydot``` -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea962cb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 8))\n",
    "gini_tree = tree.plot_tree(model_tree_gini, max_depth = 1);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50d28f72",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 8))\n",
    "entropy_tree = tree.plot_tree(model_tree_entropy, max_depth = 5);"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e4079680",
   "metadata": {},
   "source": [
    "### Pruning\n",
    "\n",
    "Limiting how far a tree can grow using hyperparameters like `max_depth` or `max_leaf_nodes` can help prevent overfitting, but they can lead to trees with high bias that can underfit the training data.\n",
    "\n",
    "Another way to address overfitting is to train a deep tree and then prune it back. This is done using the `ccp_alpha` hyperparameter. This is the cost complexity parameter. The cost complexity is the size of the tree. This is analogous to the regularization (hyper)parameter we saw with Ridge and Lasso. A higher value of thehyperparameter means more regularization and a less complex model which is less likely to over fit.\n",
    "\n",
    "We saw that the optimal entropy tree above was rather deep. But we can prune it back."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "884904f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "ccp_alpha = 0.05\n",
    "entropy_pruned = DecisionTreeClassifier(max_depth=best_depth_entropy, criterion ='entropy', ccp_alpha=ccp_alpha)\n",
    "entropy_pruned.fit(X_train, y_train)\n",
    "entropy_pruned.score(X_test, y_test)\n",
    "tree.plot_tree(entropy_pruned);"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "788fcc74",
   "metadata": {},
   "source": [
    "Minimal cost complexity pruning recursively finds the node with the ‚Äúweakest link‚Äù. The weakest link is characterized by an effective alpha, where the nodes with the smallest effective alpha are pruned first. To get an idea of what values of ccp_alpha could be appropriate, scikit-learn provides [DecisionTreeClassifier.cost_complexity_pruning_path](https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html#sklearn.tree.DecisionTreeClassifier.cost_complexity_pruning_path) that returns the effective alphas and the corresponding total leaf impurities at each step of the pruning process. As alpha increases, more of the tree is pruned, which increases the total impurity of its leaves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9d265b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = model_tree_entropy.cost_complexity_pruning_path(X_train, y_train)\n",
    "ccp_alphas, impurities = path.ccp_alphas, path.impurities"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c3f2de8b",
   "metadata": {},
   "source": [
    "In the following plot, the maximum effective alpha value is removed, because it is the trivial tree with only one node."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b007531",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.plot(ccp_alphas[:-1], impurities[:-1], marker=\"o\", drawstyle=\"steps-post\")\n",
    "ax.set_xlabel(\"effective alpha\")\n",
    "ax.set_ylabel(\"total impurity of leaves\")\n",
    "ax.set_title(\"Total Impurity vs effective alpha for training set\");"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "729e0a67",
   "metadata": {},
   "source": [
    "Next, we train a decision tree using the effective alphas. The last value in ccp_alphas is the alpha value that prunes the whole tree, leaving the tree, clfs[-1], with one node."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6831341d",
   "metadata": {},
   "outputs": [],
   "source": [
    "clfs = []\n",
    "for ccp_alpha in ccp_alphas:\n",
    "    clf = DecisionTreeClassifier(random_state=0, ccp_alpha=ccp_alpha)\n",
    "    clf.fit(X_train, y_train)\n",
    "    clfs.append(clf)\n",
    "print(\n",
    "    \"Number of nodes in the last tree is: {} with ccp_alpha: {}\".format(\n",
    "        clfs[-1].tree_.node_count, ccp_alphas[-1]\n",
    "    )\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3ef84d40",
   "metadata": {},
   "source": [
    "For the remainder of this example, we remove the last element in clfs and ccp_alphas, because it is the trivial tree with only one node. Here we show that the number of nodes and tree depth decreases as alpha increases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f16e801b",
   "metadata": {},
   "outputs": [],
   "source": [
    "clfs = clfs[:-1]\n",
    "ccp_alphas = ccp_alphas[:-1]\n",
    "\n",
    "node_counts = [clf.tree_.node_count for clf in clfs]\n",
    "depth = [clf.tree_.max_depth for clf in clfs]\n",
    "fig, ax = plt.subplots(2, 1)\n",
    "ax[0].plot(ccp_alphas, node_counts, marker=\"o\", drawstyle=\"steps-post\")\n",
    "ax[0].set_xlabel(\"alpha\")\n",
    "ax[0].set_ylabel(\"number of nodes\")\n",
    "ax[0].set_title(\"Number of nodes vs alpha\")\n",
    "ax[1].plot(ccp_alphas, depth, marker=\"o\", drawstyle=\"steps-post\")\n",
    "ax[1].set_xlabel(\"alpha\")\n",
    "ax[1].set_ylabel(\"depth of tree\")\n",
    "ax[1].set_title(\"Depth vs alpha\")\n",
    "fig.tight_layout()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4d281268",
   "metadata": {},
   "source": [
    "When ccp_alpha is set to zero and keeping the other default parameters of DecisionTreeClassifier, the tree overfits, leading to a 100% training accuracy and 88% testing accuracy. As alpha increases, more of the tree is pruned, thus creating a decision tree that generalizes better. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fd5d742",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_scores = [clf.score(X_train, y_train) for clf in clfs]\n",
    "test_scores = [clf.score(X_test, y_test) for clf in clfs]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(20,8))\n",
    "ax.set_xlabel(\"alpha\")\n",
    "ax.set_ylabel(\"accuracy\")\n",
    "ax.set_title(\"Accuracy vs alpha for training and testing sets\")\n",
    "ax.plot(ccp_alphas, train_scores, marker=\"o\", label=\"train\", drawstyle=\"steps-post\")\n",
    "ax.plot(ccp_alphas, test_scores, marker=\"o\", label=\"test\", drawstyle=\"steps-post\")\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "589c49e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"ccp_alpha that maximizes test score: {ccp_alphas[np.argmax(test_scores)]:.5f}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "73c455a6",
   "metadata": {},
   "source": [
    "\n",
    "--------\n",
    "\n",
    "\n",
    "<div class=\"alert alert-success\">\n",
    "    <strong>üèãüèª‚Äç‚ôÇÔ∏è TEAM ACTIVITY:</strong> Tuning a Spam Detection Decision Tree </div>  \n",
    "\n",
    "**Tune some of the available decision tree hyperparameters and select the best model. Finally, evaluate your selected model on the test data.**\n",
    "\n",
    "- You must be able to justify your choice for the best model **without** reference to test performance (i.e., no tuning to the test data!)\n",
    "- Consult the [DecisionTreeClassifier documentation](https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html) to see the full list of available hyperparameters. You certainly do not need to tune all of them here!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb737db7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c745ea62",
   "metadata": {},
   "source": [
    "**Pros of Decision Trees:**\n",
    "- Very straigtforward models, easy to explain to people, even easier than linear regression.\n",
    "- Transparent models, easy to interpret\n",
    "- Not as sensitive to multicollinearity as some other models\n",
    "- Do not require scaling of data, not sensitive to variables having high difference in range\n",
    "- Can handle both numerical and caterorical predictors (in some languages like R you don't even have to encode categorical data as zeros and ones, R handles it out-of-the-box)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "38f2f591",
   "metadata": {},
   "source": [
    "**Cons of Decision Trees:**\n",
    "- Not very competitive in terms of predictive accuracy, other classification and regression approaches outperform trees.\n",
    "- Overfit very quickly.\n",
    "- Very non-robust, a small change in the data can cause a large change in the final estimated tree, In other words they suffer from high variance."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "00047434",
   "metadata": {},
   "source": [
    "What can we do to make it better?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8875b209",
   "metadata": {},
   "source": [
    "Let's say we have a set of $n$ independent observations $Z_1, Z_2, Z_3, ..., Z_n$. Each $Z_i$ has a variance of $\\sigma^2$. What would be the variance of the mean of the observations $\\bar{Z}$ ?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b82de90b",
   "metadata": {},
   "source": [
    "It would be $\\frac{\\sigma^2}{n}$, which is lower than each independent observation would have."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "19102bc5",
   "metadata": {},
   "source": [
    "## Part 2: Bagging"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d2bf0809",
   "metadata": {},
   "source": [
    "In part 2 we'll\n",
    "    2. Fit a Bagging classifer using multiple bootstrapped datasets and do majority voting. \n",
    "    3. Evaluate the model on OOB and feature importance.\n",
    "    \n",
    "Hopefully after this lab you will be able to answer the following questions: \n",
    "\n",
    "- What is the main idea behind bagging?\n",
    "- Why does bagging help with overfitting?\n",
    "- Why does bagging help to built more expressive trees?\n",
    "- What is OOB? How should we use it?\n",
    "- How can we measure feature importance with trees?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "00495fa5",
   "metadata": {},
   "source": [
    "\n",
    "*QUESTION:* Where does the word *\"Bagging\"* come from?\n",
    "\n",
    "#### Some Theory: What is bagging?\n",
    "  1. Bootstrapping: resample with replacements to get different datasets and built different models.\n",
    "  2. Do something smart to combine the different models.\n",
    "  \n",
    "One way to adjust for the high variance of the output of an experiment is to perform the experiment multiple times and then average the results. \n",
    "\n",
    " 1. **Bootstrap:** we generate multiple samples of training data, via bootstrapping. We train a full decision tree on each sample of data. \n",
    " 2. **AGGregatiING** for a given input, we output the averaged outputs of all the models for that input. \n",
    " \n",
    "This method is called **Bagging: B** ootstrap + **AGG**regat**ING**. \n",
    "\n",
    "-----------\n",
    "\n",
    "Let's bootstrap our training dataset to create multiple datasets and fit Decision Tree models to each.\n",
    "\n",
    "(Resampling: we showed live that different samples give different results for things like sums, varying more when the things we sum over have high variance themselves.)\n",
    "\n",
    "\n",
    "<img src=\"fig/bagging_array.png\" alt=\"tree_adj\" width=\"80%\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33e0c131",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stat on all data\n",
    "data_train.mean(axis=0).to_frame('mean').T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2b76571",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train.sample(frac=1., replace=True).mean(axis=0).to_frame('mean').T"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ae6fa87f",
   "metadata": {},
   "source": [
    "Now we actually fit the samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee212456",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can try different values here\n",
    "n_trees = 100\n",
    "choosen_depth = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92c66a0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a decision tree to serve as the base model in the bagged ensemble\n",
    "model = DecisionTreeClassifier(max_depth=choosen_depth)\n",
    "\n",
    "# Initializing arrays to store results\n",
    "predictions_train = np.zeros( shape = (data_train.shape[0], n_trees))\n",
    "predictions_test  = np.zeros( shape = (data_test.shape[0],  n_trees))\n",
    "\n",
    "# Conduct bootstraping iterations\n",
    "for i in range(n_trees):\n",
    "    temp = data_train.sample(frac=1, replace=True)\n",
    "    boot_X = temp.drop(['spam'], axis=1)\n",
    "    boot_y = temp['spam']\n",
    "    \n",
    "    model.fit(boot_X, boot_y)  \n",
    "    predictions_train[:,i] = model.predict(X_train)   \n",
    "    predictions_test[:,i] = model.predict(X_test)\n",
    "    \n",
    "# Make Predictions Dataframe\n",
    "columns = [\"Bootstrap-Model_\"+str(i+1) for i in range(n_trees)]\n",
    "predictions_train = pd.DataFrame(predictions_train, columns=columns)\n",
    "predictions_test = pd.DataFrame(predictions_test, columns=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8bf08e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 2, figsize=(16, 7))\n",
    "for (ax, label, predictions, y) in [\n",
    "    (axs[0], 'Training Set', predictions_train, y_train), \n",
    "    (axs[1], 'Test Set' , predictions_test , y_test ) ]:\n",
    "    \n",
    "    # Take the average\n",
    "    mean_predictions = predictions.mean(axis=1)\n",
    "    \n",
    "    # Plot the Spam\n",
    "    mean_predictions[y.values == 1].hist(density=True, histtype='step', \n",
    "                                  range=[0,1], label='Spam', lw=2, ax=ax)\n",
    "    \n",
    "    # Plot the non Spam\n",
    "    mean_predictions[y.values == 0].hist(density=True, histtype='step', \n",
    "                                  range=[0,1], label='Not-Spam', lw=2, ax=ax)\n",
    "    ax.legend(loc='upper center');\n",
    "    ax.set_xlabel(\"Average of bagged ensemble's predictions\")\n",
    "    ax.set_ylabel(\"Density\")\n",
    "    ax.set_title(label)\n",
    "plt.suptitle(\"Bagged Classification Trees\");\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8da6671a",
   "metadata": {},
   "source": [
    "And now get final predictions: majority voting!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18b9ed04",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to ensemble the prediction of each bagged decision tree model\n",
    "def get_prediction(df):\n",
    "    return np.mean(df, axis=1)>0.5\n",
    "\n",
    "#Check Accuracy of Spam Detection in Train and Test Set\n",
    "acc_bagging_training = 100*accuracy_score(y_train, get_prediction(predictions_train))\n",
    "acc_bagging_testing  = 100*accuracy_score(y_test, get_prediction(predictions_test))\n",
    "\n",
    "print(\"Bagging: \\tAccuracy, Training Set \\t: {:0.2f}%\".format(acc_bagging_training))\n",
    "print(\"Bagging: \\tAccuracy, Testing Set \\t: {:0.2f}%\".format( acc_bagging_testing))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "05ceaed4",
   "metadata": {},
   "source": [
    "Count in the above code can be use to define the number of models the voting in the dataframe should be based on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baeb95f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get Performance by Class (Lookup Confusion Matrix)\n",
    "pd.crosstab(np.array(y_test), model.predict(X_test), margins=True, rownames=['Actual'], colnames=['Predicted'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b991ecac",
   "metadata": {},
   "source": [
    "\n",
    "**Food for Thought :** Are these bagging models independent of each other, can they be trained in a parallel fashion?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6041d100",
   "metadata": {},
   "source": [
    "\n",
    "### ensemble: a group of items viewed as a whole rather than individually\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "bcf401dc",
   "metadata": {},
   "source": [
    "-------------\n",
    "\n",
    "### Let's talk about decision trees and bagging in the context of bias and variance.\n",
    "<img src=\"fig/bias_variance.png\" alt=\"split2\" width=\"40%\"/>\n",
    "<img src=\"fig/fitting.png\" alt=\"split2\" width=\"40%\"/>\n",
    "\n",
    "#### When is a decision tree underfit? When is a decision tree overfit? Let's think about this in the concept of tree depth.\n",
    "\n",
    "#### Bagging enjoys the benefits of \n",
    "- High expressiveness (by using larger trees it is able to approximate complex functions and decision boundaries).\n",
    "- Low _ _ _  by averaging the prediction of all the models thus reducing the _ _ _  in the final prediction.\n",
    "\n",
    "#### What is the weakness of bagging?\n",
    "- In practice, the ensemble of trees tend to be **highly ___**\n",
    "- When could my bagging model be underfit? In what way does this apply to other ensemble methods?\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9d66d145",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "# Part 3: OOB\n",
    "\n",
    "*QUESTION:* \n",
    "- What is out-of-bag (OOB) error? \n",
    "- How can we take advantage if it to improve our model's performance?\n",
    "- Why OOB is a great method?\n",
    "\n",
    "<img src=\"fig/oob.png\" alt=\"tree_adj\" width=\"60%\"/>\n",
    "\n",
    "Out-of-bag (OOB) error/Out-of-bag estimate is a method of determining the prediction error that allows the trees to be fit and validated whilst being trained.\n",
    "OOB samples can be seen as the validation set, generated by bootstrap process. So, we don‚Äôt need to do the explicit setup another validation set. Compared to CV, it has the following advantages.\n",
    "\n",
    "‚Ä¢ OOB Error prevents leakage and gives a better model with low variance.\n",
    "\n",
    "‚Ä¢ There is also lesser computational cost for OOB error as compared to CV for bagging. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cab7edd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_oob_prediction(preds, oob_counts):\n",
    "    oob_idx = oob_counts > 0\n",
    "    oob_vote = np.sum(preds[oob_idx], axis=1)/oob_counts[oob_idx]\n",
    "    return oob_vote>0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61f4b364",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating model\n",
    "model = DecisionTreeClassifier(max_depth=choosen_depth)\n",
    "\n",
    "#Initializing variables\n",
    "predictions_train = np.zeros( shape = (data_train.shape[0], n_trees))\n",
    "predictions_test  = np.zeros( shape = (data_test.shape[0],  n_trees))\n",
    "\n",
    "predictions_oob = np.zeros(shape = (data_train.shape[0], n_trees))\n",
    "oob_samples_count = np.zeros(shape = (data_train.shape[0], )) # how many times a sample is in oob\n",
    "\n",
    "oob_accuracys = []\n",
    "#Conduct bootstraping iterations\n",
    "for i in range(n_trees):\n",
    "    temp = data_train.sample(frac=1, replace=True)\n",
    "    boot_y = temp['spam']\n",
    "    boot_X = temp.drop(['spam'], axis=1)\n",
    "    \n",
    "    # Train a decision tree\n",
    "    model.fit(boot_X, boot_y)  \n",
    "    predictions_train[:,i] = model.predict(X_train)   \n",
    "    predictions_test[:,i] = model.predict(X_test)\n",
    "    \n",
    "    # Get OOB samples\n",
    "    oob_mask = ~np.isin(data_train.index, temp.index)\n",
    "    oob_temp = data_train[oob_mask]\n",
    "    X_oob = oob_temp.drop(['spam'], axis=1) \n",
    "    y_oob = oob_temp['spam']\n",
    "    oob_p = model.predict(X_oob)\n",
    "    predictions_oob[oob_mask, i] = oob_p # Update prediction results of this tree\n",
    "    oob_samples_count[oob_mask] += 1 # Increase the count of this sample being OOB\n",
    "    \n",
    "\n",
    "acc_bagging_training = 100*accuracy_score(y_train, get_prediction(predictions_train))\n",
    "acc_bagging_testing  = 100*accuracy_score(y_test, get_prediction(predictions_test))\n",
    "acc_bagging_oob = 100*accuracy_score(y_train, get_oob_prediction(predictions_oob, oob_samples_count))\n",
    "\n",
    "print(\"Bagging: \\tAccuracy, Training Set \\t: {:0.2f}%\".format(acc_bagging_training))\n",
    "print(\"Bagging: \\tAccuracy, Testing Set \\t: {:0.2f}%\".format(acc_bagging_testing))\n",
    "print(\"Bagging: \\tAccuracy, OOB Validation Set \\t: {:0.2f}%\".format(acc_bagging_oob))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ae26bfd0",
   "metadata": {},
   "source": [
    "Food for Thought :\n",
    "\n",
    "- The essence is that we should predict responses for an observation using each of the trees in which the response is OOB.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "44782620",
   "metadata": {},
   "source": [
    "# Part 4 Feature Importance"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8ace3a99",
   "metadata": {},
   "source": [
    "### Feature importance - a quick sneak peek\n",
    "\n",
    "Details will be covered in lecture on Monday\n",
    "\n",
    "Decision Tree objects have a `feature_importances_` attribute. This is a record of how much each feature's splits contributed to the reduction in the model's splitting criterion.\n",
    "\n",
    "The idea is that features whose splits reduced the criterion the most are the most important. But there are reasons to be skeptical about this approach to feature importance..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d998f1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating model\n",
    "model = DecisionTreeClassifier(max_depth=choosen_depth)\n",
    "\n",
    "#Initializing variables\n",
    "predictions_train = np.zeros( shape = (data_train.shape[0], n_trees))\n",
    "predictions_test  = np.zeros( shape = (data_test.shape[0],  n_trees))\n",
    "\n",
    "feature_imp_matrix = []\n",
    "#Conduct bootstraping iterations\n",
    "for i in range(n_trees):\n",
    "    temp = data_train.sample(frac=1, replace=True)\n",
    "    boot_y = temp['spam']\n",
    "    boot_X = temp.drop(['spam'], axis=1)\n",
    "    \n",
    "    model.fit(boot_X, boot_y)  \n",
    "    predictions_train[:,i] = model.predict(X_train)   \n",
    "    predictions_test[:,i] = model.predict(X_test)\n",
    "    \n",
    "    # Feature Importance\n",
    "    single_tree_feature_importance = model.feature_importances_\n",
    "    feature_imp_matrix.append(single_tree_feature_importance)\n",
    "\n",
    "# Save as an np.array()\n",
    "feature_imp_matrix = np.array(feature_imp_matrix)\n",
    "\n",
    "#Make Predictions Dataframe\n",
    "columns = [\"Bootstrap-Model_\"+str(i+1) for i in range(n_trees)]\n",
    "predictions_train = pd.DataFrame(predictions_train, columns=columns)\n",
    "predictions_test = pd.DataFrame(predictions_test, columns=columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6c2fdad",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_imp_mean = feature_imp_matrix.mean(axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50fe576f",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_imp_mean_sorted = list(zip(X_train.columns, feature_imp_mean))\n",
    "feature_imp_mean_sorted.sort(key = lambda x: -x[1])\n",
    "for col, val in feature_imp_mean_sorted:\n",
    "    if val > 0.01:\n",
    "        print(f'{col}: {val}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "dfec5e54",
   "metadata": {},
   "source": [
    "*QUESTION:*\n",
    "\n",
    "- For each run of the bagging algorithm, should we expect the importance of the features to be the same?\n",
    "- Why might we not always be able to trust this method for determining feature importance.\n",
    "- Can you anticipate another way to assess feature importance? (Hint: we've seen it before)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5d0d049a",
   "metadata": {},
   "source": [
    "### SKLearn's BaggingClassifier\n",
    "\n",
    "From SKlearn's [documentation](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.BaggingClassifier.html):\n",
    "\n",
    "\"A Bagging classifier is an ensemble meta-estimator that fits base classifiers each on random subsets of the original dataset and then aggregate their individual predictions (either by voting or by averaging) to form a final prediction. Such a meta-estimator can typically be used as a way to reduce the variance of a black-box estimator (e.g., a decision tree), by introducing randomization into its construction procedure and then making an ensemble out of it.\"\n",
    "\n",
    "The most important arguments are `estimator` which defines the base estimators from which the bagged ensemble is composed and well as `n_estimators`, the number of estimators in the ensemble.\n",
    "If you want access to the `oob_score_` attribute on the fitted BaggingCLassifier you will also need to set `oob_score=True` since it is `False` by default to save a bit of computation.\n",
    "\n",
    "The individual estimators in the ensemble can be accessed by the `estimators_` attribute.\n",
    "\n",
    "`warm_start=True` will cause the BaggingClassifier to re-use the previous estimators when re-fitting with a larger setting of `n_estimators`. This saves computation as you only need to fit the new trees being added to the ensemble."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d79cd71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a BaggingClassifier using a DecisionTreeClassifier as its base estimator\n",
    "bag = BaggingClassifier(estimator=DecisionTreeClassifier(),\n",
    "                  n_estimators=100,\n",
    "                  oob_score=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1044018f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit on train\n",
    "bag.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ed618a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect OOB accuracy\n",
    "print(\"OOB ACC:\", bag.oob_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d678d91e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect test accuracy\n",
    "print(\"Test ACC:\", bag.score(X_test, y_test))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "66046c98",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "    <strong>üèãüèª‚Äç‚ôÇÔ∏è TEAM ACTIVITY 2:</strong> Number of Estimator's Affect on BaggingClassifier </div>  \n",
    "\n",
    "- Create a visualization showing how the number of estimators effects the bagging classifier's train and test scores.\n",
    "- You should use the default, 'full-depth' trees as your base estimators.\n",
    "- There are many ways to accomplish this!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47e9bfdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3cab54d1",
   "metadata": {},
   "source": [
    "ü§î **Closing Questions**:\n",
    "- Might there be something wrong with using accuracy to evaluate our spam classifier?\n",
    "- Can you think of a way to further reduce the variance of the ensemble model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b060131b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
